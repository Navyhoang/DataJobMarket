{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation of Data\n",
    "----\n",
    "For web-scraping data, clean up includes: \n",
    "1. removing duplicates \n",
    "2. adding country index numbers \n",
    "3. normalizing company locations to city and state\n",
    "\n",
    "For University ranking data, clean up includes: \n",
    "1. removing all other country's university \n",
    "2. keeping latest data (removing all other year)\n",
    "3. adding country index numbers\n",
    "\n",
    "For mental health data, clean up includes: \n",
    "1. normalizing all data (Gender and blanks) \n",
    "2. adding country index\n",
    "3. removing all other country's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd \n",
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Market Data - CA, US, SG, AU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = [\"SG\", \"CA\", \"US\", \"AU\"]\n",
    "# Country Index = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_num = 1 \n",
    "\n",
    "for x in country: \n",
    "    #import loaded csv\n",
    "    filepath = f\"../Clean Data/{x}-JobMarket.csv\"\n",
    "    df = pd.read_csv(filepath, index_col=0)\n",
    "    \n",
    "    #Cleaning:\n",
    "    \n",
    "    #removing jobs that have more than one unique job title index \n",
    "    #lots of data with duplicates - will remove duplicates but will keep the last entry\n",
    "    #i.e. if one job is labeled as both Machine Learning and Data Analyst, the Machine Learning label entry will be kept\n",
    "    #ranking will be Machine Learning(index=4), Data Engineer(index=3), Data Scientist(index=2), and then Data Analyst(index=1) \n",
    "    #(ranking is based on how specific each name is)\n",
    "    df = df.drop_duplicates(subset=['Job ID'], keep='last')\n",
    "    \n",
    "    #set job id as index (now unique)\n",
    "    df = df.set_index(\"Job ID\")\n",
    "    \n",
    "    #creating country index \n",
    "    df[\"Country\"] = index_num\n",
    "    index_num = index_num + 1\n",
    "    \n",
    "    #df to csv \n",
    "    df.to_csv(f\"../Transformed Data/{x}-JobMarket-Transformed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining all the data into one csv\n",
    "\n",
    "filepathCA = \"../Transformed Data/CA-JobMarket-Transformed.csv\"\n",
    "dfCA = pd.read_csv(filepathCA, index_col=0)\n",
    "\n",
    "filepathAU = \"../Transformed Data/AU-JobMarket-Transformed.csv\"\n",
    "dfAU = pd.read_csv(filepathAU, index_col=0)\n",
    "\n",
    "filepathUS = \"../Transformed Data/US-JobMarket-Transformed.csv\"\n",
    "dfUS = pd.read_csv(filepathUS, index_col=0)\n",
    "\n",
    "filepathSG = \"../Transformed Data/SG-JobMarket-Transformed.csv\"\n",
    "dfSG = pd.read_csv(filepathSG, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing location into City and State "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-8b45bb1d6252>:2: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "  dfCA[\"City\"], dfCA[\"State\"] = dfCA[\"Company Location\"].str.split(\", \", 1).str\n",
      "<ipython-input-5-8b45bb1d6252>:5: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "  dfAU[\"City\"], dfAU[\"State\"] = dfAU[\"Company Location\"].str.rsplit(\" \", 1).str\n",
      "<ipython-input-5-8b45bb1d6252>:8: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "  dfUS[\"City\"], dfUS[\"State\"] = dfUS[\"Company Location\"].str.split(\", \", 1).str\n",
      "<ipython-input-5-8b45bb1d6252>:9: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "  dfUS[\"State\"], dfUS[\"Zip Code\"] = dfUS[\"State\"].str.split(\" \", 1).str\n"
     ]
    }
   ],
   "source": [
    "# Spliting Canada company location into City and Province/State\n",
    "dfCA[\"City\"], dfCA[\"State\"] = dfCA[\"Company Location\"].str.split(\", \", 1).str\n",
    "\n",
    "# Spliting Australia company location into City and Province/State\n",
    "dfAU[\"City\"], dfAU[\"State\"] = dfAU[\"Company Location\"].str.rsplit(\" \", 1).str\n",
    "\n",
    "# Spliting USA company location into City, State and others (Like zip code)\n",
    "dfUS[\"City\"], dfUS[\"State\"] = dfUS[\"Company Location\"].str.split(\", \", 1).str\n",
    "dfUS[\"State\"], dfUS[\"Zip Code\"] = dfUS[\"State\"].str.split(\" \", 1).str\n",
    "\n",
    "# Defining Singapore location info from company location and country \n",
    "dfSG[\"City\"] = dfSG[\"Company Location\"]\n",
    "dfSG[\"State\"] = \"Singapore\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate four df into one\n",
    "df = dfCA.append(dfAU)\n",
    "df = df.append(dfUS)\n",
    "df = df.append(dfSG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_location</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p_ecae2dcad8f17d8b</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Data &amp; Systems Analyst</td>\n",
       "      <td>Protein Industries Canada</td>\n",
       "      <td>Regina, SK</td>\n",
       "      <td>Regina</td>\n",
       "      <td>SK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pj_12dccdfbb8ef0da5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Junior Data Analyst - LOCAL | MTL</td>\n",
       "      <td>BDP CALL CENTER</td>\n",
       "      <td>Vaudreuil-Dorion, QC</td>\n",
       "      <td>Vaudreuil-Dorion</td>\n",
       "      <td>QC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pj_7837ad55c28258ea</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Pipeline Inline-Inspection Data Analyst (ILI L...</td>\n",
       "      <td>Onstream Pipeline Inspection Services Inc.</td>\n",
       "      <td>Calgary, AB</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_05719d87a0059bf7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Data and Reporting Analyst</td>\n",
       "      <td>Nunavut Government</td>\n",
       "      <td>Iqaluit, NU</td>\n",
       "      <td>Iqaluit</td>\n",
       "      <td>NU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_bf4bd5f13d04a674</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Specialist-Data Visualization</td>\n",
       "      <td>Canadian Red Cross</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_c9a71595fbad1ebd</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>CRO - Digital Bank</td>\n",
       "      <td>Pure Hong Kong</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_ae6a40daf0546a81</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Senior Data Scientist - Image Processing &amp; Com...</td>\n",
       "      <td>BIOFOURMIS SINGAPORE PTE. LTD.</td>\n",
       "      <td>Jurong Island</td>\n",
       "      <td>Jurong Island</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_1693547ea84bdc32</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Principal Data Scientist (NLP)</td>\n",
       "      <td>Randstad</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_81eb5501dcf512e5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Materials Specialist #SGUnitedTraineeships #SGUP</td>\n",
       "      <td>BECTON DICKINSON MEDICAL (S) PTE LTD</td>\n",
       "      <td>Jurong Island</td>\n",
       "      <td>Jurong Island</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_6692e89a1083804e</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>G. TECH PTE. LTD.</td>\n",
       "      <td>Hougang</td>\n",
       "      <td>Hougang</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9871 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     job_title_id  country_id  \\\n",
       "job_id                                          \n",
       "p_ecae2dcad8f17d8b              1           2   \n",
       "pj_12dccdfbb8ef0da5             1           2   \n",
       "pj_7837ad55c28258ea             1           2   \n",
       "p_05719d87a0059bf7              1           2   \n",
       "p_bf4bd5f13d04a674              1           2   \n",
       "...                           ...         ...   \n",
       "p_c9a71595fbad1ebd              4           1   \n",
       "p_ae6a40daf0546a81              4           1   \n",
       "p_1693547ea84bdc32              4           1   \n",
       "p_81eb5501dcf512e5              4           1   \n",
       "p_6692e89a1083804e              4           1   \n",
       "\n",
       "                                                             job_title  \\\n",
       "job_id                                                                   \n",
       "p_ecae2dcad8f17d8b                              Data & Systems Analyst   \n",
       "pj_12dccdfbb8ef0da5                  Junior Data Analyst - LOCAL | MTL   \n",
       "pj_7837ad55c28258ea  Pipeline Inline-Inspection Data Analyst (ILI L...   \n",
       "p_05719d87a0059bf7                          Data and Reporting Analyst   \n",
       "p_bf4bd5f13d04a674                       Specialist-Data Visualization   \n",
       "...                                                                ...   \n",
       "p_c9a71595fbad1ebd                                  CRO - Digital Bank   \n",
       "p_ae6a40daf0546a81   Senior Data Scientist - Image Processing & Com...   \n",
       "p_1693547ea84bdc32                      Principal Data Scientist (NLP)   \n",
       "p_81eb5501dcf512e5    Materials Specialist #SGUnitedTraineeships #SGUP   \n",
       "p_6692e89a1083804e                                  Software Developer   \n",
       "\n",
       "                                                   company_name  \\\n",
       "job_id                                                            \n",
       "p_ecae2dcad8f17d8b                    Protein Industries Canada   \n",
       "pj_12dccdfbb8ef0da5                             BDP CALL CENTER   \n",
       "pj_7837ad55c28258ea  Onstream Pipeline Inspection Services Inc.   \n",
       "p_05719d87a0059bf7                           Nunavut Government   \n",
       "p_bf4bd5f13d04a674                           Canadian Red Cross   \n",
       "...                                                         ...   \n",
       "p_c9a71595fbad1ebd                               Pure Hong Kong   \n",
       "p_ae6a40daf0546a81               BIOFOURMIS SINGAPORE PTE. LTD.   \n",
       "p_1693547ea84bdc32                                     Randstad   \n",
       "p_81eb5501dcf512e5         BECTON DICKINSON MEDICAL (S) PTE LTD   \n",
       "p_6692e89a1083804e                            G. TECH PTE. LTD.   \n",
       "\n",
       "                         company_location              city      state  \n",
       "job_id                                                                  \n",
       "p_ecae2dcad8f17d8b             Regina, SK            Regina         SK  \n",
       "pj_12dccdfbb8ef0da5  Vaudreuil-Dorion, QC  Vaudreuil-Dorion         QC  \n",
       "pj_7837ad55c28258ea           Calgary, AB           Calgary         AB  \n",
       "p_05719d87a0059bf7            Iqaluit, NU           Iqaluit         NU  \n",
       "p_bf4bd5f13d04a674                 Canada            Canada        NaN  \n",
       "...                                   ...               ...        ...  \n",
       "p_c9a71595fbad1ebd              Singapore         Singapore  Singapore  \n",
       "p_ae6a40daf0546a81          Jurong Island     Jurong Island  Singapore  \n",
       "p_1693547ea84bdc32              Singapore         Singapore  Singapore  \n",
       "p_81eb5501dcf512e5          Jurong Island     Jurong Island  Singapore  \n",
       "p_6692e89a1083804e                Hougang           Hougang  Singapore  \n",
       "\n",
       "[9871 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formatting column names \n",
    "df.columns = ['job_title_id','job_title','company_name','company_location','country_id','city','state','zip_code']\n",
    "\n",
    "# Keep required columns only\n",
    "df = df[['job_title_id','country_id','job_title','company_name', 'company_location','city','state']]\n",
    "\n",
    "# Set df index name\n",
    "df.index.names=[\"job_id\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "df.to_csv(f\"../Transformed Data/AllJobMarket-Transformed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Location Table for Location API import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-12fe8ced8965>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  location_df.drop_duplicates(inplace=True, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "country_id     0\n",
       "city           0\n",
       "state         38\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing a dataframe with unique city, state information\n",
    "location_df = df[[\"country_id\", \"city\", \"state\"]]\n",
    "location_df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "# Check the number of null values in State column\n",
    "location_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inversely select to get dataframe with no NaN rows. Reset index. Export to csv\n",
    "location_summary = location_df[~location_df[\"state\"].isnull()]\n",
    "location_summary.reset_index(inplace=True, drop=True)\n",
    "location_summary.to_csv(\"../Transformed Data/location-summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mental Health Data Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling in Data \n",
    "filepath = f\"../Clean Data/MentalHealthSurvey.csv\"\n",
    "df = pd.read_csv(filepath, index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace blanks with \"N/A\"\n",
    "df = df.fillna(\"N/A\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting only required four contry information\n",
    "df = df.loc[(df[\"Country\"] == \"Canada\") | (df[\"Country\"] == \"Australia\") | (df[\"Country\"] == \"Singapore\") | (df[\"Country\"] == \"United States\")]\n",
    "\n",
    "#checking that all four countries are still in df\n",
    "df[\"Country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = [\"Singapore\", \"Canada\", \"United States\", \"Australia\"]\n",
    "#Country Index = [1, 2, 3, 4]\n",
    "\n",
    "for index_num, country in enumerate(country_list):   \n",
    "    #replacing with country index number \n",
    "    df[\"Country\"]= np.where((df.Country == country), (index_num + 1), df.Country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing gender entry \n",
    "female = [\"Female\", \"female\", \"F\", \"f\", \"Female \", \"Femake\", \"Trans woman\", \"Cis Female\", \"Trans-female\", \"cis-female/femme\", \n",
    "          \"queer/she/they\", \"Trans-female\" \"Cis Female\", \"Woman\", \"woman\", \"Female (trans)\", \"Female (cis)\", \"femail\"]\n",
    "male = [\"M\", \"Male\", \"male\", \"m\", \"Male-ish\", \"maile\", \"Cis Male\", \"Male (CIS)\", \"Make\", \"male leaning androgynous\", \"Male \", \n",
    "        \"Man\", \"Mail\", \"msle\", \"cis male\"]\n",
    "other = [\"Guy (-ish) ^_^\", \"p\", \"non-binary\", \"Nah\", \"Genderqueer\", \"Other\"]\n",
    "\n",
    "for gender in female:   \n",
    "    #replacing with country index number \n",
    "    df[\"Gender\"]= np.where((df.Gender == gender), \"Female\", df.Gender)\n",
    "\n",
    "for gender in male:   \n",
    "    #replacing with country index number \n",
    "    df[\"Gender\"]= np.where((df.Gender == gender), \"Male\", df.Gender)\n",
    "\n",
    "for gender in other:   \n",
    "    #replacing with country index number \n",
    "    df[\"Gender\"]= np.where((df.Gender == gender), \"Other\", df.Gender)\n",
    "\n",
    "df[\"Gender\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['timestamp', 'age', 'gender', 'country_id', 'state', 'self_employed',\n",
    "       'family_history', 'treatment', 'work_interfere', 'no_employees',\n",
    "       'remote_work', 'tech_company', 'benefits', 'care_options',\n",
    "       'wellness_program', 'seek_help', 'anonymity', 'leave',\n",
    "       'mental_health_consequence', 'phys_health_consequence', 'coworkers',\n",
    "       'supervisor', 'mental_health_interview', 'phys_health_interview',\n",
    "       'mental_vs_physical', 'obs_consequence', 'comments']\n",
    "\n",
    "df = df[['timestamp', 'age', 'gender', 'country_id', 'state', 'self_employed',\n",
    "       'family_history', 'treatment', 'work_interfere', 'no_employees',\n",
    "       'remote_work', 'tech_company', 'benefits', 'care_options',\n",
    "       'wellness_program', 'seek_help', 'anonymity', 'leave',\n",
    "       'mental_health_consequence', 'phys_health_consequence', 'coworkers',\n",
    "       'supervisor', 'mental_health_interview', 'phys_health_interview',\n",
    "       'mental_vs_physical']]\n",
    "\n",
    "# Change index name\n",
    "df.index.names = [\"sample_id\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Transformed Data/MentalHealth-Transformed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## University Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing in Data \n",
    "filepath = f\"../Clean Data/UniversityData.csv\"\n",
    "df = pd.read_csv(filepath, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing country with index numbers\n",
    "\n",
    "country_list = [\"Singapore\", \"Canada\", \"USA\", \"Australia\"]\n",
    "#Country Index = [1, 2, 3, 4]\n",
    "index_num = 1\n",
    "\n",
    "for country_name in country_list:   \n",
    "    #replacing with country index number \n",
    "    df[\"country\"]= np.where((df.country == country_name), index_num, df.country)\n",
    "    index_num = index_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping data on the four countries \n",
    "\n",
    "df = df.loc[(df[\"country\"] == 1) | (df[\"country\"] == 2) | (df[\"country\"] == 3) | (df[\"country\"] == 4)]\n",
    "\n",
    "#checking that all four countries are still in df\n",
    "df[\"country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only the latest data (year 2014)\n",
    "latest_df = df.loc[df[\"year\"]==2014]\n",
    "latest_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting column names \n",
    "\n",
    "df.columns = ['world_rank', 'institution', 'country_id', 'national_rank',\n",
    "       'quality_of_education', 'alumni_employment', 'quality_of_faculty',\n",
    "       'publications', 'influence', 'citations', 'broad_impact', 'patents',\n",
    "       'score', 'year']\n",
    "\n",
    "df = df[['institution', 'world_rank', 'country_id', 'national_rank',\n",
    "       'quality_of_education', 'alumni_employment', 'quality_of_faculty',\n",
    "       'publications', 'influence', 'citations', 'broad_impact', 'patents',\n",
    "       'score', 'year']]\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Transformed Data/University-Transformed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
